{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "#        IMPORTS\n",
    "# ============================\n",
    "import re\n",
    "import statistics\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "#     HELPER FUNCTIONS\n",
    "# ============================\n",
    "def count_tokens(line, delimiter):\n",
    "    tokens = re.split(delimiter, line.strip())\n",
    "    return len([t for t in tokens if t])\n",
    "\n",
    "def is_numeric(token):\n",
    "    try:\n",
    "        float(token)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "    if \"�\" in token:\n",
    "        parts = [p.strip() for p in token.split(\"�\") if p.strip()]\n",
    "        if len(parts) == 2:\n",
    "            return all(is_numeric(p) for p in parts)\n",
    "        elif len(parts) == 1:\n",
    "            return is_numeric(parts[0])\n",
    "    return False\n",
    "\n",
    "def numeric_ratio(line, delimiter):\n",
    "    tokens = [t for t in re.split(delimiter, line.strip()) if t]\n",
    "    if not tokens:\n",
    "        return 0.0\n",
    "    return sum(is_numeric(t) for t in tokens) / len(tokens)\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count) if lst else None\n",
    "\n",
    "def safe_mean(x):\n",
    "    return statistics.mean(x) if len(x) > 0 else 0\n",
    "\n",
    "def safe_var(x):\n",
    "    return statistics.variance(x) if len(x) > 1 else 0\n",
    "\n",
    "def safe_cv(x):\n",
    "    if len(x) == 0:\n",
    "        return 0\n",
    "    mean_val = safe_mean(x)\n",
    "    if mean_val == 0:\n",
    "        return 0\n",
    "    return safe_var(x) ** 0.5 / mean_val\n",
    "\n",
    "def compute_interval_overlap(interval1, interval2):\n",
    "    start1, end1 = interval1\n",
    "    start2, end2 = interval2\n",
    "    return max(0, min(end1, end2) - max(start1, start2))\n",
    "\n",
    "def intervals_overlap(interval1, interval2):\n",
    "    return max(interval1[0], interval2[0]) < min(interval1[1], interval2[1])\n",
    "\n",
    "def generate_row_pattern(tokens):\n",
    "    return ''.join('N' if is_numeric(tok) else 'S' for tok in tokens)\n",
    "\n",
    "def get_token_intervals_multi(line):\n",
    "    tokens = []\n",
    "    token_counts = {}\n",
    "    parts = re.split(r'(\\s{2,})', line)\n",
    "    pos = 0\n",
    "    for part in parts:\n",
    "        if re.fullmatch(r'\\s{2,}', part):\n",
    "            pos += len(part)\n",
    "        elif part:\n",
    "            start = pos + 1\n",
    "            end = pos + len(part)\n",
    "            base = part.strip()\n",
    "            token_counts[base] = token_counts.get(base, 0) + 1\n",
    "            tokens.append({\n",
    "                \"key\": f\"{base} {token_counts[base]}\" if token_counts[base] > 1 else base,\n",
    "                \"display\": base,\n",
    "                \"interval\": (start, end)\n",
    "            })\n",
    "            pos += len(part)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "#        CORE FUNCTIONS\n",
    "# ============================\n",
    "def segregate_blocks(lines, start_idx, end_idx):\n",
    "    blocks = []\n",
    "    block = None\n",
    "    block_idx = 0\n",
    "\n",
    "    for i in range(start_idx, end_idx):\n",
    "        line = lines[i]\n",
    "        if line.strip():\n",
    "            if block is None:\n",
    "                block = {\n",
    "                    \"idx\": block_idx,\n",
    "                    \"start\": i,\n",
    "                    \"end\": None,\n",
    "                    \"lines\": [],\n",
    "                    \"block_type\": None,\n",
    "                    \"delimiter\": None,\n",
    "                    \"headers\": [],\n",
    "                    \"header_extent\": 0,\n",
    "                    \"title\": None,\n",
    "                    \"df\": None,\n",
    "                    \"used_as_header_for\": [],\n",
    "                    \"stats\": {},\n",
    "                    \"row_patterns\": [],\n",
    "                    \"modal_token_count\": 0,\n",
    "                    \"token_count_cv\": 0.0\n",
    "                }\n",
    "            block[\"lines\"].append({\n",
    "                \"line_idx\": i,\n",
    "                \"text\": line,\n",
    "                \"count_multispace_tokens\": count_tokens(line, r\"\\s{2,}\"),\n",
    "                \"count_single_tokens\": count_tokens(line, r\"\\s+\"),\n",
    "                \"count_tab_tokens\": count_tokens(line, r\"\\t\"),\n",
    "                \"numeric_multispace_ratio\": numeric_ratio(line, r\"\\s{2,}\"),\n",
    "                \"numeric_single_ratio\": numeric_ratio(line, r\"\\s+\"),\n",
    "                \"numeric_tab_ratio\": numeric_ratio(line, r\"\\t\"),\n",
    "                \"line_len\": len(line)\n",
    "            })\n",
    "        elif block is not None:\n",
    "            block[\"end\"] = i - 1\n",
    "            blocks.append(block)\n",
    "            block_idx += 1\n",
    "            block = None\n",
    "\n",
    "    if block is not None:\n",
    "        block[\"end\"] = end_idx - 1\n",
    "        blocks.append(block)\n",
    "\n",
    "    return blocks\n",
    "\n",
    "# def compute_statistics(block):\n",
    "    # get = lambda attr: [line[attr] for line in block[\"lines\"]]\n",
    "    # s, m, t = get(\"count_single_tokens\"), get(\"count_multispace_tokens\"), get(\"count_tab_tokens\")\n",
    "    # ns, nm, nt = get(\"numeric_single_ratio\"), get(\"numeric_multispace_ratio\"), get(\"numeric_tab_ratio\")\n",
    "    # lens = get(\"line_len\")\n",
    "    # block[\"stats\"] = {\n",
    "    #     \"mean_single_tokens\": statistics.mean(s), \"var_single_tokens\": statistics.variance(s), \"cv_single_tokens\": safe_cv(s),\n",
    "    #     \"mean_multispace_tokens\": statistics.mean(m), \"var_multispace_tokens\": statistics.variance(m), \"cv_multispace_tokens\": safe_cv(m),\n",
    "    #     \"mean_tab_tokens\": statistics.mean(t), \"var_tab_tokens\": statistics.variance(t), \"cv_tab_tokens\": safe_cv(t),\n",
    "    #     \"mean_line_len\": statistics.mean(lens), \"var_line_len\": statistics.variance(lens), \"cv_line_len\": safe_cv(lens),\n",
    "    #     \"mean_numeric_single\": statistics.mean(ns), \"mean_numeric_multispace\": statistics.mean(nm), \"mean_numeric_tab\": statistics.mean(nt)\n",
    "    # }\n",
    "\n",
    "def compute_statistics(block):\n",
    "    s = []\n",
    "    m = []\n",
    "    t = []\n",
    "    ns = []\n",
    "    nm = []\n",
    "    nt = []\n",
    "    lens = []\n",
    "\n",
    "    for line in block[\"lines\"]:\n",
    "        s.append(line[\"count_single_tokens\"])\n",
    "        m.append(line[\"count_multispace_tokens\"])\n",
    "        t.append(line[\"count_tab_tokens\"])\n",
    "        ns.append(line[\"numeric_single_ratio\"])\n",
    "        nm.append(line[\"numeric_multispace_ratio\"])\n",
    "        nt.append(line[\"numeric_tab_ratio\"])\n",
    "        lens.append(line[\"line_len\"])\n",
    "\n",
    "\n",
    "    block[\"stats\"] = {\n",
    "        \"mean_single_tokens\": safe_mean(s),\n",
    "        \"var_single_tokens\": safe_var(s),\n",
    "        \"cv_single_tokens\": safe_cv(s),\n",
    "\n",
    "        \"mean_multispace_tokens\": safe_mean(m),\n",
    "        \"var_multispace_tokens\": safe_var(m),\n",
    "        \"cv_multispace_tokens\": safe_cv(m),\n",
    "\n",
    "        \"mean_tab_tokens\": safe_mean(t),\n",
    "        \"var_tab_tokens\": safe_var(t),\n",
    "        \"cv_tab_tokens\": safe_cv(t),\n",
    "\n",
    "        \"mean_line_len\": safe_mean(lens),\n",
    "        \"var_line_len\": safe_var(lens),\n",
    "        \"cv_line_len\": safe_cv(lens),\n",
    "\n",
    "        \"mean_numeric_single\": safe_mean(ns),\n",
    "        \"mean_numeric_multispace\": safe_mean(nm),\n",
    "        \"mean_numeric_tab\": safe_mean(nt)\n",
    "    }\n",
    "\n",
    "\n",
    "def detect_header_extent(block, delimiter):\n",
    "    patterns, title_line = [], None\n",
    "    for i, line in enumerate(block[\"lines\"]):\n",
    "        tokens = [t for t in re.split(delimiter, line[\"text\"].strip()) if t]\n",
    "        pattern = generate_row_pattern(tokens)\n",
    "        patterns.append(pattern)\n",
    "        if i == 0 and pattern == \"S\":\n",
    "            title_line = i\n",
    "    start_i = title_line + 1 if title_line is not None else 0\n",
    "    extent = 0\n",
    "    for pattern in patterns[start_i:]:\n",
    "        if all(c == \"S\" for c in pattern): extent += 1\n",
    "        else: break\n",
    "    return extent, title_line\n",
    "\n",
    "def merge_headers_by_overlap(token_maps):\n",
    "    base_row = token_maps[0]\n",
    "    merged_headers = [{\"name\": tok[\"display\"], \"interval\": tok[\"interval\"]} for tok in base_row]\n",
    "    for row in token_maps[1:]:\n",
    "        for tok in row:\n",
    "            matched = False\n",
    "            for hdr in merged_headers:\n",
    "                if intervals_overlap(hdr[\"interval\"], tok[\"interval\"]):\n",
    "                    hdr[\"name\"] += \" \" + tok[\"display\"]\n",
    "                    hdr[\"interval\"] = (min(hdr[\"interval\"][0], tok[\"interval\"][0]), max(hdr[\"interval\"][1], tok[\"interval\"][1]))\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                merged_headers.append({\"name\": tok[\"display\"], \"interval\": tok[\"interval\"]})\n",
    "    return sorted(merged_headers, key=lambda x: x[\"interval\"][0])\n",
    "\n",
    "def extract_headers(block, delimiter):\n",
    "    extent, title_line = detect_header_extent(block, delimiter)\n",
    "    block[\"header_extent\"] = extent\n",
    "    block[\"title\"] = block[\"lines\"][title_line][\"text\"] if title_line is not None else None\n",
    "    if extent == 0:\n",
    "        return [], 0\n",
    "    header_lines = block[\"lines\"][title_line+1:title_line+1+extent] if title_line is not None else block[\"lines\"][:extent]\n",
    "    if extent == 1:\n",
    "        token_objs = get_token_intervals_multi(header_lines[0][\"text\"])\n",
    "        return [{\"name\": t[\"display\"], \"interval\": t[\"interval\"]} for t in token_objs], extent\n",
    "    token_maps = [get_token_intervals_multi(line[\"text\"]) for line in header_lines]\n",
    "    return merge_headers_by_overlap(token_maps), extent\n",
    "\n",
    "def generate_df(headers, header_extent, lines, delimiter):\n",
    "    data_lines = lines[header_extent:]\n",
    "    col_names = [h[\"name\"] for h in headers]\n",
    "    rows = []\n",
    "    for line in data_lines:\n",
    "        tokens = [t.strip() for t in re.split(delimiter, line[\"text\"].strip()) if t.strip()]\n",
    "        rows.append(tokens)\n",
    "    return pd.DataFrame(rows, columns=col_names)\n",
    "\n",
    "def assign_tokens_by_overlap(headers, lines, delimiter):\n",
    "    n_cols, n_rows = len(headers), len(lines)\n",
    "    matrix = [[None for _ in range(n_cols)] for _ in range(n_rows)]\n",
    "    col_names = [h[\"name\"] for h in headers]\n",
    "    for i, line in enumerate(lines):\n",
    "        tokens = get_token_intervals_multi(line[\"text\"])\n",
    "        for tok in tokens:\n",
    "            best_match = max(\n",
    "                range(n_cols),\n",
    "                key=lambda j: compute_interval_overlap(tok[\"interval\"], headers[j][\"interval\"]),\n",
    "                default=None\n",
    "            )\n",
    "            if best_match is not None:\n",
    "                matrix[i][best_match] = (matrix[i][best_match] or \"\") + (\" \" if matrix[i][best_match] else \"\") + tok[\"display\"]\n",
    "    return pd.DataFrame(matrix, columns=col_names)\n",
    "\n",
    "def process_block(blocks, block_idx):\n",
    "    block = blocks[block_idx]\n",
    "    compute_statistics(block)\n",
    "    mode_multi = most_common([l[\"count_multispace_tokens\"] for l in block[\"lines\"]])\n",
    "    mean_numeric_single = block[\"stats\"][\"mean_numeric_single\"]\n",
    "    if mean_numeric_single < 0.3:\n",
    "        if mode_multi > 1:\n",
    "            if len(block[\"lines\"]) < 5:\n",
    "                headers, _ = extract_headers(block, r\"\\s{2,}\")\n",
    "                block[\"headers\"], block[\"block_type\"] = headers, \"header-only\"\n",
    "                return\n",
    "            block[\"block_type\"] = \"narrative\"\n",
    "            return\n",
    "        elif mode_multi == 1:\n",
    "            block[\"block_type\"] = \"narrative\"\n",
    "            return\n",
    "\n",
    "    cv_multi = block[\"stats\"][\"cv_multispace_tokens\"]\n",
    "    cv_tab = block[\"stats\"][\"cv_tab_tokens\"]\n",
    "    mode_tab = most_common([l[\"count_tab_tokens\"] for l in block[\"lines\"]])\n",
    "\n",
    "    delimiter = r\"\\t\" if cv_tab == 0 and mode_tab > 1 else r\"\\s{2,}\" if cv_multi == 0 and mode_multi > 1 else None\n",
    "    if delimiter:\n",
    "        block[\"delimiter\"] = delimiter\n",
    "        headers, extent = extract_headers(block, delimiter)\n",
    "        block[\"headers\"], block[\"header_extent\"] = headers, extent\n",
    "        if extent == 0:\n",
    "            for prev in reversed(blocks[:block_idx]):\n",
    "                if prev[\"block_type\"] == \"header-only\":\n",
    "                    prev_headers = prev[\"headers\"]\n",
    "                    prev_width = len(prev_headers)\n",
    "                    data_mode = most_common([count_tokens(line[\"text\"], delimiter) for line in block[\"lines\"]])\n",
    "                    df = generate_df(prev_headers, 0, block[\"lines\"], delimiter) if data_mode == prev_width else assign_tokens_by_overlap(prev_headers, block[\"lines\"], delimiter)\n",
    "                    block[\"df\"], block[\"block_type\"] = df, \"data\"\n",
    "                    prev[\"used_as_header_for\"].append(block[\"idx\"])\n",
    "                    return\n",
    "            block[\"block_type\"] = \"narrative\"\n",
    "            return\n",
    "        block[\"df\"] = generate_df(headers, extent, block[\"lines\"], delimiter)\n",
    "        block[\"block_type\"] = \"complete-tabular\"\n",
    "        return\n",
    "\n",
    "    delimiter = r\"\\s{2,}\"\n",
    "    block[\"delimiter\"] = delimiter\n",
    "    headers, extent = extract_headers(block, delimiter)\n",
    "    block[\"headers\"], block[\"header_extent\"] = headers, extent\n",
    "    if extent > 0:\n",
    "        data_lines = block[\"lines\"][extent:]\n",
    "        token_counts = [count_tokens(l[\"text\"], delimiter) for l in data_lines]\n",
    "        new_cv = safe_cv(token_counts)\n",
    "        block[\"df\"] = generate_df(headers, extent, block[\"lines\"], delimiter) if new_cv == 0 else assign_tokens_by_overlap(headers, data_lines, delimiter)\n",
    "        block[\"block_type\"] = \"complete-tabular\"\n",
    "    else:\n",
    "        for prev in reversed(blocks[:block_idx]):\n",
    "            if prev[\"block_type\"] == \"header-only\":\n",
    "                prev_headers = prev[\"headers\"]\n",
    "                prev_width = len(prev_headers)\n",
    "                data_mode = most_common([count_tokens(l[\"text\"], delimiter) for l in block[\"lines\"]])\n",
    "                df = generate_df(prev_headers, 0, block[\"lines\"], delimiter) if data_mode == prev_width else assign_tokens_by_overlap(prev_headers, block[\"lines\"], delimiter)\n",
    "                block[\"df\"], block[\"block_type\"] = df, \"data\"\n",
    "                prev[\"used_as_header_for\"].append(block[\"idx\"])\n",
    "                return\n",
    "        block[\"block_type\"] = \"narrative\"\n",
    "\n",
    "# ============================\n",
    "#        ENTRY POINT\n",
    "# ============================\n",
    "def parse(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    lines = text.splitlines()\n",
    "    i = next((j for j, line in enumerate(lines) if line.startswith(\"DATA:\")), None)\n",
    "    if i is None:\n",
    "        raise ValueError(\"No 'DATA:' line found. Not a templated NOAA file.\")\n",
    "    blocks = segregate_blocks(lines, i + 1, len(lines))\n",
    "    for idx in range(len(blocks)):\n",
    "        process_block(blocks, idx)\n",
    "    return blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = parse(\"test.txt\")\n",
    "\n",
    "for block in blocks:\n",
    "    print(block[\"headers\"])\n",
    "    print(block[\"title\"])\n",
    "    print(block[\"block_type\"])\n",
    "    display(block[\"df\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = parse(\"test2.txt\")\n",
    "\n",
    "for block in blocks:\n",
    "    print(block[\"headers\"])\n",
    "    print(block[\"title\"])\n",
    "    print(block[\"block_type\"])\n",
    "    display(block[\"df\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = parse(\"test3.txt\")\n",
    "\n",
    "for block in blocks:\n",
    "    print(block[\"headers\"])\n",
    "    print(block[\"title\"])\n",
    "    print(block[\"block_type\"])\n",
    "    display(block[\"df\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
